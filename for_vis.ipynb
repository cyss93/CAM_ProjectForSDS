{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from utils import visualize_cam, Normalize\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    cv2.imshow(\"title\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid2(net_name, output_dir,data_name):\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    if net_name == 'vgg':\n",
    "        net_model_dict = dict(type='vgg', arch=vgg, layer_name='features_29', input_size=(224, 224))\n",
    "    elif net_name == 'alexnet':\n",
    "        net_model_dict = dict(type='alexnet', arch=alexnet, layer_name='features_11', input_size=(224, 224))\n",
    "    elif net_name == 'resnet':\n",
    "        net_model_dict = dict(type='resnet', arch=resnet, layer_name='layer4', input_size=(224, 224))\n",
    "    elif net_name == 'densenet':\n",
    "        net_model_dict = dict(type='densenet', arch=densenet, layer_name='features_norm5', input_size=(224, 224))\n",
    "    elif net_name == 'squeezenet':\n",
    "        net_model_dict = dict(type='squeezenet', arch=squeezenet, layer_name='features_12_expand3x3_activation', input_size=(224, 224))\n",
    "    elif net_name == 'efficientnet':\n",
    "        net_model_dict = dict(type='efficientnet', arch=efficientnet, layer_name='_blocks 54 _bn2', input_size=(224, 224))\n",
    "\n",
    "    for i in range(16):\n",
    "        img_name = files[i]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "        pil_img = PIL.Image.open(img_path)\n",
    "\n",
    "        if len(np.asarray(pil_img).shape) == 3:\n",
    "            torch_img = torch.from_numpy(np.asarray(pil_img)).permute(2, 0, 1).unsqueeze(0).float().div(255)\n",
    "        else :\n",
    "            np_img = np.asarray(pil_img)\n",
    "            np_img = cv2.cvtColor(np_img,cv2.COLOR_GRAY2RGB)\n",
    "            torch_img = torch.from_numpy(np_img).permute(2, 0, 1).unsqueeze(0).float().div(255)\n",
    "        torch_img = F.upsample(torch_img, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        normed_torch_img = normalizer(torch_img)\n",
    "\n",
    "        gradcam_pp = GradCAMpp(net_model_dict, True)\n",
    "        mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "        heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "\n",
    "        file_name = '{}.jpeg'.format(i)\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        save_image(result_pp,output_path)\n",
    "\n",
    "    images = []\n",
    "    trans1 = transforms.ToTensor()\n",
    "\n",
    "    for i in range(16):\n",
    "        file_name = '{}.jpeg'.format(i)\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "        images.append(torch.stack([trans1(PIL.Image.open(output_path))], 0))\n",
    "        \n",
    "    images = make_grid(torch.cat(images, 0), nrow=4)\n",
    "    \n",
    "    if net_name == 'vgg':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_v_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)\n",
    "    elif net_name == 'alexnet':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_a_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)\n",
    "    elif net_name == 'resnet':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_r_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)\n",
    "    elif net_name == 'densenet':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_d_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)\n",
    "    elif net_name == 'squeezenet':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_s_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)\n",
    "    elif net_name == 'efficientnet':\n",
    "        grid_output_path = os.path.join(output_dir, \"grid_e_{}.jpeg\".format(data_name))\n",
    "        save_image(images, grid_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (6): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b7',num_classes=2)\n",
    "efficientnet.load_state_dict(torch.load(\"pth/0819/efficientnetch.pth\",map_location='cpu'))\n",
    "\n",
    "alexnet = models.alexnet()\n",
    "num_ftrs = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "alexnet.load_state_dict(torch.load(\"pth/0819/alexnetch.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "alexnet.eval()\n",
    "\n",
    "vgg = models.vgg16()\n",
    "vgg.classifier[6] = nn.Linear(4096,2)\n",
    "vgg.load_state_dict(torch.load(\"pth/0819/vgg16ch.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "vgg.eval()\n",
    "\n",
    "resnet = models.resnet18()\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "resnet.load_state_dict(torch.load(\"pth/0819/resnet18ch.pth\",map_location='cpu'))\n",
    "\n",
    "densenet = models.densenet161()\n",
    "densenet.classifier = nn.Linear(2208, 2)\n",
    "densenet.load_state_dict(torch.load(\"pth/0819/densenet161ch.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "densenet.eval()\n",
    "\n",
    "squeezenet = models.squeezenet1_1()\n",
    "squeezenet.classifier[1]  = nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet.num_classes = 2\n",
    "squeezenet.load_state_dict(torch.load(\"pth/0819/squeezenet1_1ch.pth\",map_location='cpu'))\n",
    "squeezenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_dir = 'dataset/chest_xray/val/PNEUMONIA/'\n",
    "files = os.listdir(img_dir)\n",
    "\n",
    "make_grid2('vgg','outputs/chest/pneumonia/','ch')\n",
    "make_grid2('alexnet','outputs/chest/pneumonia/','ch')\n",
    "make_grid2('resnet','outputs/chest/pneumonia/','ch')\n",
    "make_grid2('densenet','outputs/chest/pneumonia/','ch')\n",
    "make_grid2('squeezenet','outputs/chest/pneumonia/','ch')\n",
    "make_grid2('efficientnet','outputs/chest/pneumonia/','ch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {int(0):'NORMAL', int(1):'PNEUMONIA'}\n",
    "logit = efficientnet(normed_torch_img)\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "probs = probs.numpy()\n",
    "idx = idx.numpy()\n",
    "for i in range(0, 2):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dog&cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (6): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b7',num_classes=2)\n",
    "efficientnet.load_state_dict(torch.load(\"pth/0819/efficientnetcd.pth\",map_location='cpu'))\n",
    "\n",
    "alexnet = models.alexnet()\n",
    "num_ftrs = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "alexnet.load_state_dict(torch.load(\"pth/0819/alexnetcd.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "alexnet.eval()\n",
    "\n",
    "vgg = models.vgg16()\n",
    "vgg.classifier[6] = nn.Linear(4096,2)\n",
    "vgg.load_state_dict(torch.load(\"pth/0819/vgg16cd.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "vgg.eval()\n",
    "\n",
    "resnet = models.resnet18()\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "resnet.load_state_dict(torch.load(\"pth/0819/resnet18cd.pth\",map_location='cpu'))\n",
    "\n",
    "densenet = models.densenet161()\n",
    "densenet.classifier = nn.Linear(2208, 2)\n",
    "densenet.load_state_dict(torch.load(\"pth/0819/densenet161cd.pth\",map_location='cpu')) # use my model parameter and use cpu\n",
    "densenet.eval()\n",
    "\n",
    "squeezenet = models.squeezenet1_1()\n",
    "squeezenet.classifier[1]  = nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet.num_classes = 2\n",
    "squeezenet.load_state_dict(torch.load(\"pth/0819/squeezenet1_1cd.pth\",map_location='cpu'))\n",
    "squeezenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_dir = 'dataset/cat-and-dog/val/cats/' #change!\n",
    "files = os.listdir(img_dir)\n",
    "\n",
    "make_grid2('vgg','outputs/cat_and_dog/cat/','cd')\n",
    "make_grid2('alexnet','outputs/cat_and_dog/cat/','cd')\n",
    "make_grid2('resnet','outputs/cat_and_dog/cat/','cd')\n",
    "make_grid2('densenet','outputs/cat_and_dog/cat/','cd')\n",
    "make_grid2('squeezenet','outputs/cat_and_dog/cat/','cd')\n",
    "make_grid2('efficientnet','outputs/cat_and_dog/cat/','cd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(model,net_name):\n",
    "    corrects = 0\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = corrects.double() / dataset_sizes['val']\n",
    "\n",
    "    print('{}: Acc: {:.4f}'.format(net_name, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet: Acc: 0.9250\n",
      "squeezenet: Acc: 0.9297\n",
      "vgg: Acc: 0.9391\n",
      "resnet: Acc: 0.9172\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset/chest_xray/'\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "get_acc(alexnet,'alexnet')\n",
    "get_acc(squeezenet,'squeezenet')\n",
    "get_acc(vgg,'vgg')\n",
    "get_acc(resnet,'resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet : 57012034\n",
      "squeezenet : 723522\n",
      "vgg : 134268738\n",
      "resnet : 11177538\n",
      "densenet : 26476418\n",
      "efficientnet : 63792082\n"
     ]
    }
   ],
   "source": [
    "print(\"alexnet : {}\".format(count_parameters(alexnet)))\n",
    "print(\"squeezenet : {}\".format(count_parameters(squeezenet)))\n",
    "print(\"vgg : {}\".format(count_parameters(vgg)))\n",
    "print(\"resnet : {}\".format(count_parameters(resnet)))\n",
    "print(\"densenet : {}\".format(count_parameters(densenet)))\n",
    "print(\"efficientnet : {}\".format(count_parameters(efficientnet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
